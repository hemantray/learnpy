{\rtf1\ansi\ansicpg1251\deff0\nouicompat\deflang1058{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Riched20 10.0.16299}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\f0\fs22\lang9 All right, so first,\par
let's see what is the distribution of the sample mean,\par
because we're trying to estimate the mean.\par
Let's look and we're trying to approximate it\par
by the sample mean.\par
Let's see what the distribution of the sample mean is.\par
So remember, as we said,\par
that by the central limit theorem,\par
if we take X1 plus Xn,\par
subtract n mu so that this has zero mean,\par
and then normalize by sigma times the square root of n,\par
so it has,\par
then it has standard deviation one.\par
Then this will be roughly normal zero one.\par
That was the first slide.\par
Now what we can do is we can multiply this.\par
We want to forget this,\par
we want to get the sample mean,\par
which is X1 plus Xn divided by n.\par
So let's first multiply by sigma\par
divided by the square root of n.\par
Sigma will cancel.\par
Square root of n will become n.\par
So what this will give us is X1 plus Xn\par
minus n mu divided by n, right?\par
Because sigma disappeared and this became n, okay?\par
So now because we multiplied by sigma\par
over the square root of n,\par
the mean, this had mean zero.\par
It's multiplied by this number,\par
but stays zero therefore.\par
And the variance gets multiplied by sigma squared over n,\par
okay?\par
So we get that this value is distributed normal\par
mean zero and variance sigma squared over n, okay?\par
Now, so now what we want to do\par
is we want to get rid of this subtraction,\par
so we're going to put as what are we subtracting by,\par
we're subtracting by mu because n cancels.\par
So we're going to add mu,\par
and when we add mu here,\par
what we get is that X1 plus Xn\par
and so on divided by n is distributed normally,\par
and the variance doesn't change when we add the constant,\par
but the mean will change by mu,\par
so this will become the mean.\par
So what that tells us is that if we take a look\par
at X1 plus Xn over n is roughly normal with mean mu\par
and variance sigma squared over n, okay?\par
So and this is just the sample mean, okay?\par
So this tells us the sample mean distribution,\par
if we look at the sample mean,\par
this value is distributed normal with mean mu\par
and variance sigma squared over n, okay?\par
Now, again, this is not,\par
this math is not too complicated,\par
but if you just want to understand it intuitively,\par
you can, as well.\par
So, because X average is just the average.\par
What does it have?\par
It's first of all, it's roughly normal.\par
And that was the central limit theorem,\par
that's what it told us, right?\par
Because it told us that this was normal\par
and all we do is just take a normal\par
and multiply it by a constant,\par
it will stay roughly normal.\par
Add a constant, it will stay roughly normal.\par
So the sample mean is going to be roughly normal.\par
We need to calculate its mean\par
and its standard deviation.\par
So first of all, its mean,\par
what is the mean?\par
So the mean is going to be,\par
so, I apologize,\par
the mean is going to be mu, right?\par
So, and that's what I should've written here.\par
In fact, that's what I wrote here.\par
So the expected value of X,\par
of X hat is mu, right?\par
It's, I should've written it's centered at the,\par
either the distribution mean or the population mean, okay?\par
So it's centered at mu,\par
which is again not surprising,\par
because we have, we're adding n variables,\par
so when we do that,\par
the expectation is n times mu,\par
and then we divide by n,\par
so it's just mu, okay?\par
And then the variance,\par
when we do this,\par
so what will happen to the variance,\par
the variance is going to be,\par
we're adding n things here,\par
so the variance is going to be n\par
times the individual variance,\par
but we divide by n,\par
so the variance goes down by a factor of n squared,\par
so the variance is going to be\par
the original variance sigma over n.\par
I don't know if I wrote it.\par
Yes, perfect.\par
So the variance is going to be sigma squared over n, right?\par
Because we added each of Xis has variance sigma squared,\par
we added n of them,\par
so it's n times sigma squared,\par
and then we normalized by n,\par
the variance goes down by a factor of n squared,\par
so it's sigma squared over n, okay?\par
And therefore the standard deviation is\par
the square root of this,\par
which is sigma divided by the square root of n, right?\par
Okay, cool.\par
Now, and this is, by the way,\par
is called standard error.\par
I'm not emphasizing these terms because I think\par
I just want you to understand, you know,\par
the logic and, you know,\par
maybe the math rather than terminology.\par
And another terminology that people use\par
is the distribution of the sample mean\par
is called the sampling distribution of the sample mean.\par
So the distribution of the statistic, the sample mean,\par
is called a sample-mean distribution.\par
So it's, this one's the standard distribution\par
of the sample mean, okay?\par
But we don't need to worry about this.\par
All right, okay.\par
So one thing that I want you to remember, though,\par
is that when we take the average,\par
then the standard deviation of the sample mean,\par
of X bar,\par
is the original standard deviation\par
divided by the square root of n.\par
This we'll see a couple times coming up,\par
so just remember that.\par
So if we had a random variable\par
with standard deviation sigma,\par
when we take the average of n of those,\par
the standard deviation is going to go down\par
by a factor of the square root of n.\par
So this is what we have here.\par
And the standard deviation of the sample mean\par
is the standard deviation of the original random variable\par
and, but it's actually,\par
it gets smaller because we're taking averages,\par
and it gets smaller by a factor of the square root of n.\par
Cool.\par
So the next thing,\par
and the only thing, in fact,\par
that we have left to do\par
is to notice that proximity is reciprocal.\par
It's obviously quite obvious\par
and hopefully math will not confuse us.\par
So what we have shown until now is that X is,\par
that the average is going to be roughly near mu,\par
because that's what we were saying.\par
The standard deviation is going to be centered at mu.\par
The standard deviation is going to go down.\par
So the average is likely going to be near mu, okay?\par
But what that tells us is that mu is going to be near X,\par
right?\par
Because if X is near mu,\par
then mu is near X.\par
This is a reciprocal property, okay?\par
So we're just going to do some math to convince us of that,\par
but maybe we don't really need.\par
So what we know is that X is going to be\par
between mu minus a and mu plus a, okay?\par
And what that tells us is that X minus mu,\par
the absolute value of X minus mu is less than or equal to a,\par
right?\par
That if X is within a from mu,\par
then X minus mu,\par
the difference between them is at most a.\par
This shows us that this property is symmetric.\par
As we all know,\par
proximity is reciprocal, is symmetric.\par
And so this means that mu is going to be\par
between X minus a and X plus a, right?\par
Because X minus mu is a,\par
so that means that mu is between X minus,\par
the average X,\par
this is the sample mean minus a\par
and the sample mean plus a.\par
And what's happening here is this.\par
What we have been arguing for this,\par
in this lecture so far\par
is we have argued that if we take the average,\par
the sample average, sample mean,\par
it's going to be in this interval,\par
it's going to be near mu,\par
between mu minus a and plus a, okay?\par
And what we are showing here is by the same coin,\par
the mean is going to be very close\par
to the sample we've got.\par
We know it's going to be between X minus a, X plus a.\par
So let's show a couple of just examples.\par
So here is the mean mu\par
and here is mu minus a and mu plus a.\par
And here is X average,\par
and X average, if it falls inside the mean here,\par
so it's in this interval, okay?\par
And because it's in this interval,\par
that means that if we took X average\par
and we took minus a and plus a,\par
then mu is going to fall inside this range.\par
So in other words,\par
we can say that if X falls within this red interval here\par
that we had calculated before,\par
with probability 95%,\par
it's also correct to say\par
that the mean mu will fall within X.\par
This is what we are going to observe.\par
Plus minus a, okay?\par
Because these two things are the same.\par
And conversely,\par
if X does not fall in this region,\par
then mu is not going to fall in this interval,\par
where we added plus and minus a, okay?\par
So what we're saying is hopefully simpler\par
than these equations, okay?\par
And what we have shown before\par
was that the sample mean is going to be distributed roughly,\par
should add roughly here,\par
normal with mean mu\par
and standard deviation sigma over the square root of n.\par
That's the standard deviation of X hat, okay?\par
So with high probability X hat is near mu here,\par
and by the same token,\par
we can say that with high probability,\par
mu is near X hat, okay?\par
Those are the same.\par
Sorry about that.\par
These are the same.\par
All right, okay.\par
So basically what this says is that if Isaac Newton,\par
or a physicist like Isaac Newton,\par
tells us that the apple,\par
which hides behind my picture.\par
There's an apple here behind me.\par
Trust me on that.\par
If the apple...\par
There it is.\par
They tells that the apple doesn't fall far from the tree.\par
The statisticians like Jerzy Neyman,\par
who came up with confidence interval,\par
what they say is the tree does not grow far from the apple.\par
So if we calculated before\par
and we saw that the apple is going to be\par
very close to the tree,\par
we're going to observe where the apple fell\par
and we're going to know where the tree is, right?\par
Okay, so let's look at confidence intervals there.\par
So what we have calculated is\par
we say that with probability p,\par
if zp is going to be the value for the,\par
that if someone gives us p,\par
we're going to calculate the value\par
for the standard normal random variable\par
such that with probability p,\par
we're going to be,\par
the z is going to be between minus zp and plus zp.\par
So with probability p,\par
therefore X hat is going to be zp standard deviations\par
from its mean,\par
so it's going to be between mu minus zp\par
times the standard deviation of X hat.\par
X bar, sorry.\par
And mu plus zp\par
times the standard deviation of the sample mean, okay?\par
Because zp again is the value that we had calculated before\par
that says that if we look at Z,\par
the standard normal random variable,\par
it's going to be from minus zp to plus zp\par
with probability p,\par
and that's the same as the probability that X\par
is within zp standard deviations from its mean,\par
so X is between mu minus zp\par
times the standard deviation of X bar\par
and mu plus zp times the standard deviation of X bar.\par
But again,\par
by what we said before,\par
X minus,\par
this means that X minus mu is at most\par
zp times the standard deviation of X bar,\par
and this will mean that mu is going to be\par
within X bar minus zp,\par
minus the same distance here,\par
zp times sigma,\par
so here we're using the fact that sigma X bar\par
is sigma over the square root of n,\par
so mu is going to be between X minus zp\par
times sigma over the square root of n\par
and X bar plus zp times sigma over the square root of n\par
with probability p, okay?\par
All right, so just to make sure,\par
we, given some probability p,\par
we find zp such that z is between minus zp and plus zp\par
with probability p.\par
So z is within this many standard deviations away.\par
And that means that X bar is going to be\par
within this many standard deviations away from its mean mu,\par
okay?\par
And now we're going to use the fact\par
that if X is close to mu\par
and mu is close to X by the same value,\par
so mu is between X minus zp times the standard deviation,\par
sigma over the square root of n,\par
and X plus zp times the standard deviation,\par
which is again sigma over the square root of n.\par
Okay, so that's all there is to it.\par
So if you look at the notebook that we have for you,\par
you'll see a bunch of things,\par
and one of them is how to,\par
is an experiment here.\par
So what we do is we take a random variable,\par
which in this case is normal.\par
It'll make things cleaner.\par
Sorry.\par
And then we can change the sample size n\par
and we can change the number of experiments\par
so that we get the correct value,\par
and we see,\par
and the confidence interval here is 85%.\par
So when you have confidence interval of 85%,\par
we calculate the interval here\par
such that we expect the mean to be within this,\par
that much of the interval close to the sample mean.\par
So here is the distribution mean,\par
which is zero,\par
because it's just a Gaussian distribution, okay?\par
And what we do here is we take a sample\par
and we calculate the sample mean,\par
and this is what we,\par
the value that we calculated before,\par
which is sigma times the value zp\par
and divided by the square root of n, okay?\par
And we get,\par
we do it so that the confidence level is 85%.\par
This is p.\par
And what we do is rewind this experiment\par
and you see that 85% of the time\par
the mean mu is going to fall within this value zp\par
times sigma divided by square root of n\par
away from the mean here,\par
and that also means that the mean is going to fall\par
within that distance from the sample mean.\par
So this happens all the green cases,\par
and in all the red cases,\par
our sample mean fell away from,\par
far away from the distribution mean\par
by more than what we allow,\par
so it's further away,\par
and therefore also the mean is not within our interval\par
that we set away from the sample mean, okay?\par
So this happens 15% of the time, all right?\par
So let's do a couple of examples\par
just to make it maybe a little clearer.\par
So suppose that the number of tweets\par
of a random Tweeter user is a random variable\par
with standard deviation two,\par
and suppose that we take a sample of 121 users\par
and find that the sample mean was 3.7.\par
So the average of this 121 users,\par
number of tweets they had per day,\par
this is the number of tweets per day.\par
Let's say it was 3.7 daily tweets.\par
And so what we want to do is we want to find\par
the 95% confidence interval for the distribution mean.\par
So we know that the sample mean,\par
we took 121 users,\par
we see that the sample mean was 3.7 for these 121 users,\par
and the question is what can we say about the actual mean\par
of the distribution?\par
And we want to find the 95% confidence interval\par
for the distribution.\par
So first of all,\par
what we do is we calculate zp,\par
which is phi inverse of one plus p over two.\par
This is the value such that if you took a normal,\par
standard normal random variable z,\par
then it will be within zp away from zero,\par
zp standard deviations.\par
It's the same case here in this case,\par
away from zero.\par
Then the probability of that is going to be p.\par
So zp is phi inverse of one plus p over two,\par
and the p that we're interested in is 95%.\par
So one plus p,\par
we've calculated it a couple times.\par
One plus p is going to be the average between 95 and 100,\par
so it's 97.5.\par
So looking at phi inverse of 0.975,\par
and we found out that it's 1.96,\par
and this is roughly, again,\par
our 68%, 97.5% rule, right?\par
Says that we need to go two standard deviations away, okay?\par
So what this says is that the probability that\par
a Gaussian random variable is going to be\par
two standard deviations away from its mean\par
is roughly going to be 95%, okay?\par
And, all right, okay.\par
Now, so we want to construct a 95% confidence interval\par
for the mean,\par
so what we do is we take the sample mean\par
and we say that the distribution mean\par
is going to be between the sample mean that we observed.\par
This is the 3.7.\par
And plus minus zp,\par
which is this value here that we found,\par
but this is for the normal random variable,\par
but we need to not look at the normal,\par
but we need to look at the distribution of X bar, right?\par
Because this is the value we calculated the mean for X bar,\par
so we need to see what is the standard deviation\par
of X bar of the sample mean, okay?\par
And notice, by the way,\par
that because we have 121 users,\par
121 is much larger than 30,\par
then we can assume that the distribution is roughly Gaussian\par
and these approximations are roughly correct, okay?\par
So probability 95% we're going to be within zp.\par
This is the value 1.96.\par
Standard deviations away from the mean,\par
or the mean is going to be within the same value\par
away from our,\par
the distribution mean will be the same distance\par
away from our sample mean here, X hat.\par
So, X bar.\par
So we just need to plug in.\par
So X bar is 3.7, so,\par
and this, by the way,\par
is called, again, margin of error.\par
Again, I'm trying not to overload you with terminology,\par
but this value is the margin of error\par
by how much we can be wrong.\par
And so this we just plug in,\par
and this will give us X bar minus z,\par
and then the standard deviation of the sample mean\par
is going to be sigma divided by square root of n.\par
So it's plus minus zp times square root of n,\par
sigma square root of n,\par
and then we just X bar, the sample mean,\par
was, is 3.7,\par
and we plug in sigma, which is two,\par
and n, which is 121.\par
So square root of n is 11,\par
and you calculate,\par
you get 3.344 and 4.056.\par
So just a couple of observations.\par
So first of all,\par
the mean that we observed was 3.7.\par
If we had a point estimate,\par
we'll just say that the mean of the distribution\par
is 3.7.\par
But that almost surely will not be correct.\par
The mean of the population.\par
That's not gonna be correct.\par
So instead we give it a value that is centered at 3.7,\par
so it's this X bar plus minus something.\par
And so it's 3.7 plus minus something,\par
and this something that we are adding and subtracting\par
is called the margin of error,\par
which is zp times the standard deviation\par
of the sample mean.\par
Zp we calculate to be 1.96.\par
That's how many standard deviations we want to be away.\par
And now we just need to calculate the standard deviation\par
of this mean of 121 users.\par
And we're told that for each user,\par
the standard deviation is two.\par
We're taking the average of 121 users,\par
so the standardization of the average\par
is going to be this sigma,\par
which is two,\par
divided by square root of 121, or 11.\par
So it's two divided by 11 multiplied by 1.96\par
and then added and subtracted from 3.7, okay?\par
So this is what we have.\par
Notice also that we say with 95% confidence\par
this is the interval.\par
We don't say 95% probability.\par
The difference between confidence and probability\par
is a little subtle,\par
and what, the reason we say confidence\par
is because we did this experiment,\par
and the sample mean is either,\par
so we gave an interval here.\par
The distribution mean or the population mean\par
is either inside this range\par
or outside this range.\par
So it's either inside,\par
in which case the probability is zero,\par
or it's outside,\par
in which the probability that it's inside is,\par
I'm sorry, it's inside,\par
it's either inside this range,\par
in which case the probability that it's inside is one,\par
or it's outside,\par
in which the probability it's inside is zero.\par
So we cannot say that the probability\par
that the mean lies in here is some value 95%.\par
This is something we could've said that,\par
when we designed this experiment,\par
that will happen with a probability of 95%.\par
But now that we've observed it,\par
it's not the probability.\par
The probability is either one or zero.\par
But what we can say is that,\par
the way we avoid this issue\par
is we say that with 95% confidence,\par
the distribution mean lies in here.\par
That means that if you repeat this experiment many times,\par
95% of the times the sample mean will be within the interval\par
that we specify, okay?\par
So again,\par
if you want, think of it as the probability,\par
but in fact it's kind of like retroactive probability.\par
We call it confidence.\par
So we designed this experiment so that 95,\par
if we did this experiment 100 times,\par
then 95% of the time we will be correct.\par
And so we have 95% confidence\par
that the mean is in this range, all right?\par
So this is one example.\par
Now let's look at a slightly different example.\par
So let's look at heart rate,\par
which is defined,\par
so heart rate is defined as the number of beats per minute,\par
so we can think of it as heart rate\par
or number of beats per minute, okay?\par
So let's say that the adult heart rate\par
has standard deviation which is 7.5 beats per minute, okay?\par
So it's some number,\par
but the standard deviation is 7.5 beats per minute.\par
Now again, typically we'll not know this value,\par
but in this lecture, as we said,\par
we assume that we know the standard deviation.\par
In the next lecture,\par
we'll see what to do when we don't know.\par
Okay, so what we want to do is,\par
rather than find someone who gives us the confidence\par
and want to find the interval,\par
what we want to see,\par
to do here is we,\par
someone gives us...\par
Sorry, someone gave us,\par
I'm sorry, someone gave us n\par
and we wanted to find the confidence interval,\par
what we want to do here is the opposite.\par
Somebody's going to give us the confidence\par
then we want to find how many samples we need to take.\par
So we want to estimate the heart rate\par
to within a margin of error\par
which is at most two beats per minute,\par
and the question is,\par
and want to do it with confidence level 90%.\par
And the question is how many samples do we need to take,\par
okay?\par
So first of all,\par
what we see here is that,\par
because we want the confidence label to be 90%,\par
then how many,\par
so what we want to be is we want our answer to be\par
within phi inverse of one plus p.\par
P is going to be 90%.\par
This is how many standard deviations away we'll be\par
from the mean if this was a normal random variable.\par
So this zp is going to be phi inverse of 0.95,\par
90 plus 1.9 plus one over two,\par
which is 1.645.\par
So what this tells us is that if we have\par
a standard normal random variable,\par
then it's going to be 1.645 away from the mean zero,\par
or 1.645 standard deviations away from its mean,\par
with probability 90%, okay?\par
Now I'm going to send the sample size.\par
So what we want is\par
we want the sample size when,\par
that gives us this,\par
and what we want is we want that the margin of error,\par
how much we're going to be away from the mean,\par
to be at most two.\par
So we know that what we're going to estimate\par
is going to be estimated mu plus zp times sigma X bar,\par
which is zp times sigma over the square root of two,\par
the square root of n,\par
and we want that to be two,\par
because if we do that,\par
then our estimate is going to be X bar,\par
the sample average,\par
plus minus this value, okay?\par
And so if we make sure that this value is two,\par
then with this probability or this confidence,\par
our, we're going to be at most two away from the mean, okay?\par
So we want zp times sigma over the square root of n\par
to be two,\par
and this tells us that n is just going to be zp,\par
we just move it here,\par
zp times sigma over two squared,\par
and zp we calculate to be 1.645,\par
sigma is 7.5,\par
and two is the number that we got here,\par
so it's 38.05.\par
So we want the sample size to be bigger than 38.05,\par
so we can take it to be 39, for example, okay?\par
So in other words,\par
what we have done is we,\par
this described confidence intervals,\par
where instead of estimate a particular value\par
for a parameter like the mean,\par
a point estimate,\par
we give an interval,\par
and we're pretty confident that we'll be in this interval,\par
and we described how to do it\par
and gave a couple of examples, okay?\par
And what we're going to do next time\par
is we're going to talk about what happens\par
when the standard deviation is not known.\par
See you then.\par
End of transcript. Skip to the start.\par
POLL\par
}
 